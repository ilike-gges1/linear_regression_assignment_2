
## Assignment Purpose and Description
This repo features two notebooks, one in Python (Linear_Regression_Py_Notebook) and one in R (Linear_Regression_R_Notebook), that input a specific data set, plots it in a scatter plot, models a linear regression line, and plots the line on the graph. I completed this assignment with an older data set before it was updated, so there is some vestigal code that still works from it. In general, the workflow was: input CSV, print CSV, plot graph, make line, plot graph + line, evaluate data. There are also two scripts, one in Python and one in R, that allow the user to input their own CSV file with two columns and plot a scatter plot with linear regression line. Both scripts also output various evaluative landmarks to better understand the data. The notebooks I wrote were not very compatable with this method, so the scripts look quite different. There are two PNG files in this repo, linear_regression_r_output.png and linear_regression_python_output.png, that show the scatterplot and linear regression line for each script, respectively. I have absolutely no idea how Rplots.pdf made its way into this folder but he isn't causing any harm, so I let him stay. I left the original export to scripts for the notebook pre-editing to have an idea what they looked like before I adjusted them for user input. There are also .html versions of the aformentioned notebooks so the code can be read outside of Jupyter Lab.

## Here, I will go further into each file:

## Linear_Regression_Py_Notebook.ipynb
I first import the csv module to read csv files. I open the csv file and give it the variable name "lr_data." I then read the lr_data file and for every row in the file I print it, so I have a table of values. This is an easy way for me to see that the file was properly read by the program. Next, I import various packages. Specifically, I import pandas, matplotlib, and numpy. Using pandas, I read the data for future permutations.For python, I used arrays to read the previous data set before this one. This code still worked, so I kept it. Using numpy, I created an array of the yearsexperience values and an array of the salary values, labeled x_lr, and y_lr, respectively. I printed this array too so I can see that this worked. Next, I created the scatter plot. I used the plt.scatter command, using x_lr and y_lr as my variables, and chose black as my color. I used the plt.title, plt.xlabel, and plt.ylabel to make my labels, and plt.show() to print the graphFor the linear regression, my previous code used the np.polyfit command from numpy. This created a linear line with x_lr as the x variable, y_lr as the y variable, and a linearity of 1. It printed the slope and intercept. I am not sure if these values are 100% accurate but I left it in regardless. I used the same commands that created the scatterplot and assigned the slope and intercept values from the np.polyfit command. I then created a line using the abline_value command, using the slope and intercept defined earlier and an x variable from x_lr. I then plotted it in red. Again, I am not sure this is an accurate linear regression value, so in case it is not, I continued with the class example.I imported the LinearRegression command from sklearn. I created a model of linear regression and fitted it using the YearsExperience and Salary data. I then put this line on a graph, and accidentally input a line with no data points. I kept it to show that the line worked.To round it all out, I created the scatter plot, plotted the line, titled the graph, and ALSO plotted my original linear regression line. It looks like the line was accurate as there was complete overlap. I then output the R square value using the model score command.

## Linear_Regression_R_Notebook.ipynb
Like python, I completed this with older data sets, and then had to redo it. Some of the code still worked. Also like python, I started by reading the CSV file. I created a lr_data variable that is a read of the csv file. I then printed the file, to again show that the correct data was being read. I then used the plot command to plot the YearsExperience and Salary from lr_data, colored it, labeled it, and gave it a fun little data point marker, all using the various modifiers for the plot command. My original linear regression did not jive with the new data, so I rebuilt the linear regression code from the class example. I redid the graph to make sure it works, created a model using the lm command, comparing the Salary and YearsExperience data pulling from lr_data. I added the ggplot2 library, and using ggplot, I created a prediction model from the x and y variables. I am not exactly sure how this code works. I then titled the graphs and axes, and printed a summary. 

## linear_regression_python.py
This is mostly from the class example as I could not get my arrays to work with inputting your own data. I REALLY wanted them to work but relented after several attempts of x_lr being undefined when it looked like it was defined. First, I import several modules. I import sys, pandas, matplotlib, and numpy. The code that allows the executable script to run with the inputs of file name, x_col (renamed x_var), and y_col (renamed y_var) are written. Like the notebook, I have pandas read the file, import CSV module, open it as lr_data, read lr_data, and for every row print the file. Therefore, I know the data I am putting into the script is accurate and the initial code works. There is a party with the plt commands next. First, I plt.scatter to plot the scatter plot with the generic x_var and y_var data. Then, I title the plt.title to name the plot y_var vs x_var. I plt.xlabel and plt.ylabel the axes with their headers. Using sklearn, I import the linearregression tool and create a linear regression model. I fit the data to the model, and then plt.plot the model with a separate color. I save the figure using the plt.savefig command. Lastly, I am interested in the R square, so I create a rsquare variable using the model.score command from the notebook and print it so it is below the data table printed earlier. 

## linear_regression_r.r
This is mostly from the class example as I could not get my original code to work, something with xlim not working when I had no xlim value. I added the usual argument command that allowed the user to type in a csv file, their x column header, and their y column header. I then read and printed the data, which was a good indicator that my initial argument code worked and that the correct data was being read into the code. The formula and model code is a bit confusing, but similar to the notebook it creates a model of a linear regression reading the data from lr_data. For formula, I am not really sure what that does. I then used ggplot to make the graph in a much more concise way than my initial notebook. I gave the summary at the end so we still had some metrics for how the analysis went, and used the ggsave command to output the graph as a png.

## linear_regression_python_output.png
Graph output from the py script. 
![Python Output Graph](linear_regression_python_output.png)

## linear_regression_r_output.png
Graph output from the r script.
![R Output Graph](linear_regression_r_output.png)

## Original_Py_Notebook_Output.py
The raw script output from the Py notebook .ipynb file. This DOES NOT WORK.

## Original_R_Notebook_Output.r
The raw script output from the R notebook .ipynb file. This DOES NOT WORK.

## regression_data.csv
The data used for the exercise. It is a csv with YearsExperience and Salary columns. 

## Rplots.pdf
A pdf of the png file of the R graph. I sincerely have no idea where this came from. Did the summary command call it? 

## Tools Used
For R, I used ggplots2. For Python, I used pandas, matplotlib.pyplot, numpy, and scikit.